---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2beta2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: rybbit-clickhouse
  namespace: sensei
spec:
  interval: 15m
  chart:
    spec:
      chart: app-template
      version: 4.6.0
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system
      interval: 15m
  maxHistory: 2
  install:
    remediation:
      retries: 10
  upgrade:
    remediation:
      retries: 10
  values:
    controllers:
      rybbit-clickhouse:
        containers:
          app:
            image:
              repository: clickhouse/clickhouse-server
              tag: 26.1-alpine
            env:
              CLICKHOUSE_DB: analytics
              CLICKHOUSE_USER: default
              CLICKHOUSE_PASSWORD: ${SECRET_CLICKHOUSE_PASSWORD}
              CLICKHOUSE_DO_NOT_CHOWN: "1"
            resources:
              requests:
                cpu: 200m
                memory: 1Gi
              limits:
                memory: 4Gi
          clickhouse-backup:
            image:
              repository: altinity/clickhouse-backup
              tag: 2.6.41
            # - server for API triggered backups, - watch for scheduled backups
            command:
              - /bin/clickhouse-backup
              - watch

            env:
              LOG_LEVEL: "info"
              ALLOW_EMPTY_BACKUPS: "true"
              API_LISTEN: "0.0.0.0:7171"
              BACKUPS_TO_KEEP_LOCAL: "0"
              BACKUPS_TO_KEEP_REMOTE: "30"
              CLICKHOUSE_SKIP_TABLES: "system.*,INFORMATION_SCHEMA.*"
              CLICKHOUSE_USERNAME: default
              CLICKHOUSE_PASSWORD: ${SECRET_CLICKHOUSE_PASSWORD}
              CLICKHOUSE_HOST: "127.0.0.1"  # Use IPv4 explicitly
              CLICKHOUSE_PORT: "9000"

              WATCH_INTERVAL: "4h"  # Create backup every 24 hours
              FULL_INTERVAL: "24h"  # Full backup every day


              # AWS S3 Configuration
              REMOTE_STORAGE: s3
              S3_BUCKET: "dittofeed-backup"  # Your S3 bucket name
              S3_ACCESS_KEY: "${SECRET_SENSEI_AWS_ACCESS_KEY_ID}"  # AWS Access Key ID
              S3_SECRET_KEY: "${SECRET_SENSEI_AWS_SECRET_ACCESS_KEY}"  # AWS Secret Access Key
              S3_REGION: "${SECRET_SENSEI_AWS_S3_REGION}"  # AWS region (e.g., us-east-1)
              S3_ENDPOINT: ""  # Leave empty for AWS S3 (uses default AWS endpoints)
              S3_PATH: "rybbit/clickhouse/"  # Optional: prefix path in bucket
              S3_DISABLE_SSL: "false"  # Use HTTPS for AWS S3
              S3_FORCE_PATH_STYLE: "false"  # Use virtual-hosted-style for AWS S3

            ports:
              - name: backup-api
                containerPort: 7171

    defaultPodOptions:
      securityContext:
        runAsNonRoot: true
        runAsUser: 101
        runAsGroup: 101
        fsGroup: 101
        fsGroupChangePolicy: Always

    service:
      app:
        controller: rybbit-clickhouse
        type: LoadBalancer
        annotations:
          io.cilium/lb-ipam-ips: 192.168.3.83
        ports:
          http:
            port: 8123
          tcp:
            port: 9000

    persistence:
      data:
        existingClaim: rybbit-clickhouse
        globalMounts:
          - path: /var/lib/clickhouse
      # data:
      #   enabled: true
      #   type: nfs
      #   server: 192.168.1.3
      #   path: /volume1/network-storage/cluster/rybbit/clickhouse
      #   globalMounts:
      #     - path: /var/lib/clickhouse
      config:
        enabled: true
        type: configMap
        name: rybbit-clickhouse
        globalMounts:
          - path: /etc/clickhouse-server/config.d

    configMaps:
      config:
        enabled: true
        data:
          config.xml: |
            <clickhouse>
                <logger>
                    <level>warning</level>
                    <console>true</console>
                </logger>

                <!-- Skip check for incorrect settings to avoid configuration errors -->
                <skip_check_for_incorrect_settings>1</skip_check_for_incorrect_settings>

                <!-- Explicitly set listen hosts to avoid conflicts -->
                <listen_host>0.0.0.0</listen_host>

                <!-- Configure ports explicitly to avoid conflicts -->
                <tcp_port>9000</tcp_port>
                <http_port>8123</http_port>

                <!-- Keep only query_log with short retention, disable heavy system tables -->
                <query_log>
                    <database>system</database>
                    <table>query_log</table>
                    <partition_by>toYYYYMM(event_date)</partition_by>
                    <flush_interval_milliseconds>60000</flush_interval_milliseconds>
                    <ttl>event_date + INTERVAL 1 HOUR DELETE</ttl>
                </query_log>
                <query_thread_log remove="remove"/>
                <metric_log remove="remove"/>
                <asynchronous_metric_log remove="remove"/>
                <trace_log remove="remove"/>
                <text_log remove="remove"/>
                <part_log remove="remove"/>
                <session_log remove="remove"/>
                <processors_profile_log remove="remove"/>
                <query_views_log remove="remove"/>
                <query_metric_log remove="remove"/>
                <asynchronous_insert_log remove="remove"/>
                <error_log remove="remove"/>

                <!-- Reduce background pool sizes to limit I/O pressure -->
                <background_pool_size>16</background_pool_size>
                <background_schedule_pool_size>16</background_schedule_pool_size>

                <!-- Configure merge behavior - throttled to avoid overwhelming Ceph -->
                <merge_tree>
                    <max_bytes_to_merge_at_max_space_in_pool>1073741824</max_bytes_to_merge_at_max_space_in_pool>
                    <max_suspicious_broken_parts>50</max_suspicious_broken_parts>
                    <max_suspicious_broken_parts_bytes>1073741824</max_suspicious_broken_parts_bytes>
                    <number_of_free_entries_in_pool_to_lower_max_size_of_merge>6</number_of_free_entries_in_pool_to_lower_max_size_of_merge>
                    <max_replicated_merges_in_queue>2</max_replicated_merges_in_queue>
                    <parts_to_delay_insert>300</parts_to_delay_insert>
                    <parts_to_throw_insert>600</parts_to_throw_insert>
                </merge_tree>

                <merge_max_block_size>8192</merge_max_block_size>
                <max_bytes_to_merge_at_min_space_in_pool>1048576</max_bytes_to_merge_at_min_space_in_pool>

                <!-- Disable additional ports that are causing conflicts -->
                <interserver_http_port remove="remove"/>
                <mysql_port remove="remove"/>
                <postgresql_port remove="remove"/>
                <prometheus_port remove="remove"/>
                <port remove="remove"/>
            </clickhouse>

